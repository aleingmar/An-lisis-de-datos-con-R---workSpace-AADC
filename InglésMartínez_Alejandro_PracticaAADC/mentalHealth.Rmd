---
title: "R Notebook"
output:
  html_document:
    df_print: paged
---

## ABSTRACT

En este proyecto de AADC he tratado de realizar las siguientes tareas:

1.  Preprocesar los datos usando Caret para poder aplicar algoritmos de aprendizaje Supervisado, algoritmos de aprendizaje no supervisado y para visualizar patrones de los datos mediantes matrices de correlación.
2.  Caracterizar y representar los datos mediantes diagramas de barras
3.  Encontrar patrones en los datos mediante matrices de correlación
4.  Realizar apredizaje no supervisado aplicando los algoritmos de kmeans y clustering jerárquico.
5.  Clasificar los datos utilizando algoritmos de aprendizaje supervisado.
6.  Comparar los rendimientos de la clasificación usando redeucción de dimensialidad mediante PCA, elección de variables mediante Wrapped y clasificación con todas las variables.

# - ÍNDICE

### 1. Introducción a los datos

### 2. Exploración de los datos

### 3. Visualización y caracterización de los datos 1

### 4. Preprocesado de datos con CARET

### 5. Visualización y caracterización de los datos 2

#### 5.1 Matriz Correlación

#### 5.2 Clustering Jerárquico y Kmeans

### 6. Clasificación -\> Ansiedad

### 7. Comparativa de modelos predictivos

### 8. Clasificación con Selección de predictores - Wrapped

### 9. Clasificación con Reducción de dimensionalidad- PCA

### 10. Comparativa Clasificación Final

# - Introducción a los datos

En la actualidad, la salud mental es una de las mayores preocupaciones sanitarias para la sociedad. En especial para los jóvenes, donde el suicidio se llega a situar entre las principales causas de muerte.

En la última década se ha destapado la realidad sobre las patologías relacionadas con este ámbito y se han empezado a cuestionar los taboos que hasta entonces estas enfermedades llevaban consigo, lo que provocaba que antes se las tratasen como secundarias.

Todo esto ha permitido que se le dee por parte de los ciudadanos la importancia que requieren, y que a día de hoy se considere a estas patologías como a otras cualquiera.

El conjunto de datos utilizado en este proyecto contiene 11 características que describen la salud mental de 101 estudiantes de distintas carreras, cursos y edades.

El objetivo de nuestro proyecto será :

1.  Tratar de caracterizar y encontrar respuestas sobre los problemas de salud mental existentes en los estudiantes universitarios. (a través de la aplicación de técnicas de aprendizaje no supervisado).
2.  Tratar de predecir, y por tanto evitar de forma temprana, posibles cuadros de ansiedad en estudiantes con alto riesgo de peadecerlos. Lo que permitiría la aplicación de medidas preventivas que permitieran revertir la situación.

Las variables del conjunto de datos son:

1.  fechaMedida - fecha en la que se recogió la muestra
2.  genero - género del estudiante
3.  edad - edad del estudiante (en el momento de la medición)
4.  titulacion - carrera universitaria que cursa
5.  año - año académico que cursa
6.  calificacion - calificación obtenida durante su transcurso en la tirulació
7.  estadoCivil - si está en alguna relación sentimental
8.  depresion - si padece depresión
9.  ansiedad - si padece ansiedad
10. ataquesPanico - si padece frecuentemente ataques de pánico
11. tratamiento - si toma algún tipo de medicamento para alguna patología relaciona con la salud mental

# - Exploración de los datos

## Carga de librerías

```{r}
library(ggplot2)
library(tidyverse)

#install.packages('plotly', 'repos=http://cran.rstudio.com/ 295', dependencies=TRUE)

library(plotly)
library(caret)
library(rsample)
library(recipes)


#install.packages("corrplot")
library(corrplot)


#install.packages("C50")
library(C50)

#install.packages("ranger")

library(ranger)
```

### Lectura de datos

```{r}
#Importamos los datos y los estudiamos

datosMental<-read.csv("dataset_MentalHealth.csv")
```

### Cambio de nombre de columnas

```{r}
names(datosMental) <- c('fechaMedida', 'genero', 'edad', 'titulacion', 'año', 'calificacion', 'estadoCivil', 'depresion', 'ansiedad', 'ataquesPanico', 'tratamiento')
```

### Resumen

```{r}
str(datosMental)
head(datosMental)
dim(datosMental)
```

### Búsqueda y tratamiento de datos faltantes

```{r}

nrow(datosMental)
nrow(na.omit(datosMental))
# Contar el número total de valores faltantes
sum(is.na(datosMental))
```

```{r}
#2-> por columna
#Busco la columna que tiene algún valor faltante -> EDAD
indx <- apply(datosMental, 2, function(x) any(is.na(x)))
indx
```

```{r}
#numero de la muestra (fila) que tiene el valor perdido
which(is.na(datosMental$edad))
```

### Tratamiento MissingValue -\> Imputación

Hay un individuo con un valor perdido en la columna edad. Como nuestro dataset solo tiene 100 muestras, creo que es mejor la imputación por la media que eliminar el individuo.

```{r}
datosMental[44,'edad'] <- median(datosMental$edad, na.rm =T)
sum(is.na(datosMental))
```

# - Visualización y caracterización de los datos 1

#### Ideas

Qué porcentaje de los estudiantes que padecen depresión tienen también ansiedad?

Se tiene más ansiedad en los primeros años de carrera?

Qué porcentaje de estudiantes piden ayuda médica por edad?

### Distribución de edad

```{r}


datosMental %>%
  group_by(edad) %>%
  summarize(count = n()) %>%
  plot_ly(x =~edad, y=~count, type = 'bar',
        text = ~count,
        textposition = 'outside',
        marker = list(color = 'rgb(158,202,225)',
          line = list(color = 'black',
                 width = 1.0))) %>%
layout(title = 'Distibution of Age')
```

### Distribución de genero

```{r}

dis_gen <- datosMental %>%
  group_by(genero) %>%
  summarise(count = n(),
            percentage = round((n()/ nrow(datosMental)), digits = 4))


colors <- c('rgb(211,94,96)','rgb(114,147,203)')
Gender_PieChart <- plot_ly(data = dis_gen, labels = ~genero, values = ~percentage,
                type = 'pie', sort = F,
                textposition = 'inside',
                textinfo = 'label+percent',
                insidetextfont = list(color = 'White'),
                hoverinfo = 'text',
                text = ~count,
                marker = list(colors = colors,
                line = list(color = 'Black', width = 1)),
                showlegend = TRUE) 
Gender_PieChart <- Gender_PieChart %>% layout(title = 'Dustribución de genero')
Gender_PieChart
```

### Depresión VS Género

```{r}
datosMental %>% 
  count(genero, depresion, sort = F) %>%
  group_by(genero) %>%
  mutate(prop = round((n / sum(n)),digits = 4)) %>%
  plot_ly(x = ~genero, y=~prop, color = ~depresion, type = "bar",
          text = ~paste(genero, prop*100 ,'%'),
          textposition = 'outside') %>%
    layout(barmode = 'Stacked',
           title = 'Depresión VS Género')
```

Se observa que las mujeres tienen un índice de depresión bastante más elevado que los hombres.

### Calificaciones VS Depresion

```{r}
datosMental %>%
  count(calificacion, depresion, sort = F) %>%
  mutate(proportion = round((n/sum(n)),digits=4)) %>%
  plot_ly(x =~calificacion, y=~proportion, color = ~depresion, type = 'bar') %>%
  layout(barmode = 'Group',
         title = 'Calificaciones VS depresion')
```

Se puede observar que existe una especie de correlación entre la calificación de los estudiantes y la presencia de depresión. A medida que crecen las calificaciones aumenta la presencia de esta enfermedad.

### Titulaciones VS depresión

Titulaciones en las que haya más de dos encuestados

```{r}
datosMental %>% 
  group_by(titulacion) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  filter(count >2)
```

```{r}
datosMental %>%
  filter(grepl('BIT|KOE|BCS|Engineering|Biomedical science', titulacion)) %>%
  count(titulacion, depresion, sort = T) %>%
  group_by(titulacion) %>%
  mutate(prop = round((n / sum(n)),digits = 4)) %>%
  plot_ly(x = ~titulacion, y=~n, color = ~depresion, type = "bar",
          text = ~paste(titulacion, n),
          textposition = 'outside') %>%
  layout(barmode = 'Stacked',
         title = 'Barplot of depresion amongst the top 5 titulacions')
```

Observamos que la titulación que tiene un mayor porcentaje de estudiantes con depresión es BIT (Bachelor of Information Technology) seguido del resto de ingenierías.

Por lo que podemos deducir que los estudiantes de carreras del ámbito tecnológico tienen mayores problemas de salud mental

# - Preprocesado de datos con CARET

La imputación de los datos ya la hemos hecho previamente en la exploración de los datos

### Creación del objeto Reciped -\> Para predecir la ansiedad

Reciped es un tipo de objeto que se define en Caret para el procesamiento y al que se le aplican diferentes métodos en las diferentes fases del preprocesado.

```{r}
# No incluyo la fecha de medición
objeto_recipe_Ansiedad <- recipe(formula = ansiedad ~ genero + edad + titulacion + tratamiento + calificacion + estadoCivil + depresion + ataquesPanico,
                        data =  datosMental)
objeto_recipe_Ansiedad

```

### Normalización de los datos entre [0,1] -\> No se hacerlo con caret

```{r}
# se lo aplico a todas las var numéricas
# objeto_recipe_Ansiedad <- objeto_recipe_Ansiedad %>% step_scale(all_numeric(), -all_outcomes())

objeto_recipe_Ansiedad <- objeto_recipe_Ansiedad %>% step_center(all_numeric())
objeto_recipe_Ansiedad <- objeto_recipe_Ansiedad %>% step_scale(all_numeric())

```

### Binarización de variable categóricas -\> One hot Encoding

```{r}
# se lo aplico a todas las var categóricas
objeto_recipe_Ansiedad <- objeto_recipe_Ansiedad %>% step_dummy(all_nominal(), -all_outcomes())
```

### Entrenamiento del objeto Reciped

```{r}
trained_recipe <- prep(objeto_recipe_Ansiedad, training = datosMental)
trained_recipe
```

### Aplicación a nuestro dataset

```{r}
# no está la fecha de medida
datosMental_Limpios <- bake(trained_recipe, new_data = datosMental)

datosMental_Limpios
```

```{r}
objeto_preprocesamiento <- preProcess(datosMental_Limpios, method = c("range"), range = c(0,1))

# Aplicar el preprocesamiento a los datos
datosMental_Limpios <- predict(objeto_preprocesamiento, datosMental_Limpios)

# Ver los datos escalados
print(datosMental_Limpios)
```

# - Visualización y caracterización de los datos 2

### Matriz de correlación

```{r}
#Creo un nuevo dataset igual que el anterior pero donde voy a pasar la variable ansiedad a numérica para crear la matriz de correlación

datos_matrizCor <- datosMental_Limpios

#paso la variable ansiedad a numérica y la meto en el nuevo dataset

datos_matrizCor$ansiedad <- as.numeric(datosMental_Limpios$ansiedad)

# Genero los coeficientes de correlación

matriz_correlacion <- cor(datos_matrizCor)

#Lo represento en una matriz de correlación con todas las variables
#PROBLEMA -> es demasiada grande (no se ve bien)

corrplot(matriz_correlacion, method = "number", tl.cex = 0.5)

```

No se ve apenas nada ya que hay demasiadas variables. Pero si se puede llegar a apreciar que existe una mayor correlación entre las últimas filas y las columnas de la matriz.

Por lo que voy a hacer otra matriz de correlación pero esta vez solo con un subconjunto de variables que me permitan ampliar y ver de forma más exacta la zona más correlacionada.

```{r}

variables <- names(datos_matrizCor)
print(variables)
```

```{r}
# voy a quedarme solo con las últimas 10 variables


# Selecciono las 10 últimas variables
subconjunto_cor_list <- tail(variables, 10)

# Crear el nuevo dataset con las 10 últimas variables
subconjunto_Cor <- datos_matrizCor[, subconjunto_cor_list]

# meto también la ansiedad
subconjunto_Cor$ansiedad <- datos_matrizCor$ansiedad

# Imprimir el nuevo dataset
subconjunto_Cor

```

```{r}
subconjunto_Cor_Matriz <- cor(subconjunto_Cor)

#Lo represento en una matriz de correlación con todas las variables
#PROBLEMA -> es demasiada grande (no se ve bien)

corrplot(subconjunto_Cor_Matriz, method = "number", tl.cex = 0.5)
```

Se puede apreciar que parece que existe una más que existente correlación entre el estado civil de los estudiantes y la presencia de depresión

### Intento de clustering K-means

```{r}
# Aplicamos el algoritmo k-means con tres centros de masa y el parámetro nstar igual a 20
km_puntos <- kmeans(datos_matrizCor, centers=2, nstart=20)
km_puntos
km_puntos$cluster
#n strat es la aleatoriedad del algoritmo

# los vectores de abajo será el punto numero 1 cae en el claster 2
```

```{r}

#No me deja representarlos graficamente por el tamaño de la representación -> he intentado arreglarlo pero me ha sido imposible.


#par(mar = c(1, 1, 1, 1)) # Ajustar los márgenes a valores más pequeños

#plot(datos_matrizCor, col=km_puntos$cluster) #se obtienen tres clusters
```

#### Dispersión de clusters

Esto nos permitirá observar cual es el número óptimo de clústers para nuestro conjunto de datos.

Parece que a partir de los 3 clúster la dispersión empieza a reducirse en menor medida.

```{r}

# quiero hacer 15 ejecucuiones variando el numero d egrupos para comparar el valor de compactacion

vector_compactacion <- 0
for (i in 1:15){
  km_puntos_aux2 <- kmeans(datos_matrizCor, centers=i, nstar=20)
  vector_compactacion[i] <- km_puntos_aux2$tot.withinss

  
}

# hacemos la graficas

par(mfrow= c(1,1))



plot(1:15, vector_compactacion, type= 'b', xlab= 'Numero de clusters',
     ylab= 'valor de compactacion')
```

### Clustering Jerárquico

```{r}
#matriz de distancias
matriz_distancias <- dist(datos_matrizCor)

#se construye el dendograma
hclust_aux <- hclust(matriz_distancias)

summary(hclust_aux)
```

```{r}

plot (hclust_aux, hang = -2)
```

```{r}
# se puede costar según la altura del endograma
cutree (hclust_aux, h = 2.8)

# se puede cortar por el numero de cluster que quiero
cutree (hclust_aux, , k=3)
```

Visualizar -\> Otra vez los problemas con los margenes

```{r}

#plot(datos_matrizCor, col=cutree (hclust_aux, , k=3), main= 'Se obtienen 3 puntos')

```

# - Clasificación -\> Ansiedad

Vamos a realizar el entrenamiento y evaluación de modelos predictivos usando el paquete CARET.

Para ello, creo que la técnica de evaluación más confiable es la VALIDACIÓN CRUZADA.

## Técnica de evaluación -\> Validación Cruzada

```{r}
particiones  <- 5

set.seed(123)

control_train2 <- trainControl(method = "cv", #Validación cruzada repetida
                              number = particiones, #Dividimos conjunto en 5 partes
                              returnResamp = "final", 
                              verboseIter = FALSE)
```

## KNN

```{r}
# Hiperparámetros
hiperparametros <- data.frame(k = c(1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25))

# AJUSTE DEL MODELO
# ==============================================================================
set.seed(342)
modelo_knn <- train(ansiedad ~ ., data = datosMental_Limpios,
                    method = "knn",
                    tuneGrid = hiperparametros,
                    metric = "Accuracy",
                    trControl = control_train2)
modelo_knn
```

```{r}
ggplot(modelo_knn, highlight = TRUE) +
  scale_x_continuous(breaks = hiperparametros$k) +
  labs(title = "Evolución del accuracy del modelo KNN", x = "K") +
  theme_bw()
```

## Naive Bayes

```{r}

# 
#  # AJUSTE DEL MODELO
#  # ==============================================================================
  set.seed(342)
  modelo_nb <- train(ansiedad ~ ., data = datosMental_Limpios,
                     method = "nb",
                    metric = "Accuracy",
                    trControl = control_train2)
  modelo_nb
```

## 

## Definición Técnica de evaluación y Árbol de decisión RandomForest

```{r}
# Hiperparámetros
# min.node.size -> minimo de nodos por hoja
hiperparametros <- expand.grid(mtry = c(3, 4, 5, 7),
                               min.node.size = c(2, 3, 4, 5, 10, 15, 20, 30, 35, 40),
                               splitrule = "gini")

# AJUSTE DEL MODELO
# ==============================================================================
set.seed(342)
modelo_rf <- train(ansiedad ~ ., data = datosMental_Limpios,
                    method = "ranger",
                    tuneGrid = hiperparametros,
                    metric = "Accuracy",
                    trControl = control_train2)
modelo_rf
```

```{r}
modelo_rf$finalModel
```

```{r}
# REPRESENTACIÓN GRÁFICA
# ==============================================================================
ggplot(modelo_rf, highlight = TRUE) +
  scale_x_continuous(breaks = 1:30) +
  labs(title = "Evolución del accuracy del modelo Random Forest") +
  guides(color = guide_legend(title = "mtry"),
         shape = guide_legend(title = "mtry")) +
  theme_bw()
```

## Comparativa de modelos predictivos con datasets original (preprocesado)

```{r}
modelos <- list(KNN = modelo_knn,
                rf = modelo_rf,
                nb= modelo_nb)

resultados_resamples <- resamples(modelos)

```

```{r}
metricas_resamples <- resultados_resamples$values %>%
                         gather(key = "modelo", value = "valor", -Resample) %>%
                         separate(col = "modelo", into = c("modelo", "metrica"),
                                  sep = "~", remove = TRUE)
metricas_resamples %>% head()
```

```{r}
metricas_resamples %>%
  filter(metrica == "Accuracy") %>%
  group_by(modelo) %>% 
  summarise(media = mean(valor)) %>%
  ggplot(aes(x = reorder(modelo, media), y = media, label = round(media, 2))) +
    geom_segment(aes(x = reorder(modelo, media), y = 0,
                     xend = modelo, yend = media),
                     color = "grey50") +
    geom_point(size = 7, color = "firebrick") +
    geom_text(color = "white", size = 2.5) +
    scale_y_continuous(limits = c(0, 1)) +
    # Accuracy basal
    geom_hline(yintercept = 0.62, linetype = "dashed") +
    annotate(geom = "text", y = 0.72, x = 8.5, label = "Accuracy basal") +
    labs(title = "Validación: Accuracy medio repeated-CV",
         subtitle = "Modelos ordenados por media",
         x = "modelo") +
    coord_flip() +
    theme_bw()
```

## Selección de predictores -\> Wrapped

Probamos la opción del uso de la técnica de wrapped para ver si se puede mejorar el rendimiento calculado por los algoritmos anteriormente, cambiando la combinación de variables predictoras y buscando la mejor combinación posible.

### Wrapped usando Random Forest y validación cruzada

```{r}

#Definimos el algoritmo que utilizamos en la técnica wrapped (Random Forest) con el # parámetro functions y la técnica
ctrl_rfe <- rfeControl(functions = rfFuncs, method = "cv", number = 5,
                       returnResamp = "all", verbose = FALSE)

# Se ejecuta la eliminación recursiva de predictores
set.seed(342)
rf_rfe <- rfe(ansiedad ~ ., data = datosMental_Limpios,
              sizes = c(1:35), #tamaño de los conjuntos de predictores analizados
              metric = "Accuracy",
              # El accuracy es la proporción de clasificaciones correctas
              rfeControl = ctrl_rfe,
              ntree = 500)
# Dentro de rfe() se pueden especificar argumentos para el modelo empleado, por
# ejemplo, el hiperparámetro ntree=500.

```

```{r}
rf_rfe
```

```{r}
ggplot(data = rf_rfe$results, aes(x = Variables, y = Accuracy)) +
  geom_line() +
  scale_x_continuous(breaks  = unique(rf_rfe$results$Variables)) +
  geom_point() +
  geom_errorbar(aes(ymin = Accuracy - AccuracySD, ymax = Accuracy + AccuracySD),
                width = 0.2) +
  geom_point(data = rf_rfe$results %>% slice(which.max(Accuracy)),
             color = "red") +
  theme_bw()
```

```{r}
rf_rfe$optVariables
```

```{r}
datosMental %>%
  filter(grepl('BIT|KOE|BCS|Engineering|Biomedical science', titulacion)) %>%
  count(titulacion, ansiedad, sort = T) %>%
  group_by(titulacion) %>%
  mutate(prop = round((n / sum(n)),digits = 4)) %>%
  plot_ly(x = ~titulacion, y=~n, color = ~ansiedad, type = "bar",
          text = ~paste(titulacion, n),
          textposition = 'outside') %>%
  layout(barmode = 'Stacked',
         title = 'Barplot of depresion amongst the top 5 titulacions')
```

## PCA - KNN

```{r}
# Aplicar PCA a los datos
pca <- prcomp(datos_matrizCor, scale. = TRUE)

# Obtener el porcentaje de variabilidad explicada por cada componente
porcentaje_variabilidad <- pca$sdev^2 / sum(pca$sdev^2) * 100

# Crear el gráfico de barras
barplot(porcentaje_variabilidad, names.arg = paste0("PC", 1:length(porcentaje_variabilidad)),
        xlab = "Componente Principal", ylab = "Porcentaje de Variabilidad Explicada",
        main = "Porcentaje de Variabilidad Explicada por Componente Principal")

```

```{r}
# Obtener las 13 mejores componentes principales
componentes_principales <- pca$x[, 1:13]

# Crear un nuevo dataset con las 13 mejores componentes principales
datasetPCA <- as.data.frame(componentes_principales)

# Añadir la variable objetivo al nuevo dataset, si corresponde
datasetPCA$ansiedad <- datosMental_Limpios$ansiedad
```

```{r}

# Hiperparámetros
hiperparametros <- data.frame(k = c(1, 3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25))

# AJUSTE DEL MODELO
# ==============================================================================
set.seed(342)
modelo_knnPCA <- train(ansiedad ~ ., data = datasetPCA,
                    method = "knn",
                    tuneGrid = hiperparametros,
                    metric = "Accuracy",
                    trControl = control_train2)
modelo_knnPCA
```

## COMPARATIVA FINAL

```{r}
modelos <- list(KNN = modelo_knn,
                rf = modelo_rf,
                nb= modelo_nb,
                pcaKNN=modelo_knnPCA,
                wrapped= rf_rfe )

resultados_resamples <- resamples(modelos)

```

```{r}
metricas_resamples <- resultados_resamples$values %>%
                         gather(key = "modelo", value = "valor", -Resample) %>%
                         separate(col = "modelo", into = c("modelo", "metrica"),
                                  sep = "~", remove = TRUE)
metricas_resamples %>% head()
```

```{r}
metricas_resamples %>%
  filter(metrica == "Accuracy") %>%
  group_by(modelo) %>% 
  summarise(media = mean(valor)) %>%
  ggplot(aes(x = reorder(modelo, media), y = media, label = round(media, 2))) +
    geom_segment(aes(x = reorder(modelo, media), y = 0,
                     xend = modelo, yend = media),
                     color = "grey50") +
    geom_point(size = 7, color = "firebrick") +
    geom_text(color = "white", size = 2.5) +
    scale_y_continuous(limits = c(0, 1)) +
    # Accuracy basal
    geom_hline(yintercept = 0.62, linetype = "dashed") +
    annotate(geom = "text", y = 0.72, x = 8.5, label = "Accuracy basal") +
    labs(title = "Validación: Accuracy medio repeated-CV",
         subtitle = "Modelos ordenados por media",
         x = "modelo") +
    coord_flip() +
    theme_bw()
```
